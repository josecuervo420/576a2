{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josecuervo420/576a2/blob/main/beckassignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2QCxjpgrFVWG"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import portalocker"
      ]
    },
    {
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Define the iterator for building the vocabulary\n",
        "def yield_tokens(data_iter, special_tokens):\n",
        "    # Ensure special tokens are included in the first iteration\n",
        "    for token in special_tokens:\n",
        "        yield [token]\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Special tokens\n",
        "special_tokens = [\"<unk>\", \"<pad>\", \"<start>\", \"<end>\"]\n",
        "\n",
        "# Load the dataset iterator\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "# Build the vocabulary with special tokens\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter, special_tokens), specials=special_tokens)\n",
        "\n",
        "# Set default index for unknown tokens\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ty2xCHMlIFcN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xcRLvvIUFVWJ"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(data, n=3):\n",
        "    model = defaultdict(Counter)\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-n+1):\n",
        "            context = tuple(sentence[i:i+n-1])\n",
        "            target = sentence[i+n-1]\n",
        "            model[context][target] += 1\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_bnzmXrNFVWJ",
        "outputId": "330501d8-224c-4892-fbcf-77bd7a5d0afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lock acquired. Press Enter to release lock...\n",
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import portalocker\n",
        "with open(\"test.lock\", \"w\") as lock_file:\n",
        "    portalocker.lock(lock_file, portalocker.LOCK_EX)\n",
        "    input(\"Lock acquired. Press Enter to release lock...\")\n",
        "\n",
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CR5ywhkzFVWJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Ensure output layer matches vocab size\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])  # Assuming you want the last output for classification\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_uPVsnXZFVWJ"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def load_data(data_type='train'):\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    counter = Counter()\n",
        "    for label, line in IMDB(split=data_type):\n",
        "        counter.update(tokenizer(line))\n",
        "    # Convert the counter to a list of tokens\n",
        "    tokenized_text = [tok for tok, cnt in counter.items() for _ in range(cnt)]\n",
        "    return tokenized_text\n",
        "\n",
        "# Now, using this function, you can load and tokenize your dataset:\n",
        "tokenized_text = load_data('train')  # This should now correctly load and tokenize the text data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uerowftJFVWK"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(tokenized_text, n=3):\n",
        "    model = {}\n",
        "    for i in range(len(tokenized_text)-n):\n",
        "        gram = tuple(tokenized_text[i:i+n-1])\n",
        "        next_word = tokenized_text[i+n-1]\n",
        "        if gram not in model:\n",
        "            model[gram] = {}\n",
        "        if next_word not in model[gram]:\n",
        "            model[gram][next_word] = 0\n",
        "        model[gram][next_word] += 1\n",
        "    # Convert counts to probabilities\n",
        "    for gram in model.keys():\n",
        "        total = float(sum(model[gram].values()))\n",
        "        for word in model[gram]:\n",
        "            model[gram][word] /= total\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wSaMUwfzFVWK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model, start_text, num_words=20, n=3):\n",
        "    result = start_text.split()\n",
        "    for _ in range(num_words):\n",
        "        state = tuple(result[-(n-1):]) # Last (n-1) words\n",
        "        next_words = model.get(state, None)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choices(list(next_words.keys()), weights=next_words.values())[0]\n",
        "        result.append(next_word)\n",
        "    return ' '.join(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8_nPjMgpFVWK",
        "outputId": "a0ce25ad-2bb5-4666-f9f4-804c033a744b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n"
          ]
        }
      ],
      "source": [
        "# Example usage (adapt as necessary)\n",
        "tokenized_text = load_data('train')  # Load and tokenize your text data\n",
        "ngram_model = build_ngram_model(tokenized_text, n=3)\n",
        "\n",
        "# Generate 5 sample reviews\n",
        "for _ in range(5):\n",
        "    print(generate_text(ngram_model, \"My favorite movie\", num_words=20, n=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7omgFSEjFVWK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data_iter, vocab, tokenizer):\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        for label, text in data_iter:\n",
        "            # Ensure to handle unknown tokens, assuming vocab returns a special index for unknown tokens\n",
        "            numericalized_text = [self.vocab.get('<start>', self.vocab.get('<unk>'))] + \\\n",
        "                                 [self.vocab.get(token, self.vocab.get('<unk>')) for token in self.tokenizer(text)] + \\\n",
        "                                 [self.vocab.get('<end>', self.vocab.get('<unk>'))]\n",
        "            self.data.append((numericalized_text, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        numericalized_text, label = self.data[idx]\n",
        "        input_sequence = torch.tensor(numericalized_text[:-1], dtype=torch.long)\n",
        "        target_sequence = torch.tensor(numericalized_text[1:], dtype=torch.long)\n",
        "        return input_sequence, target_sequence, label  # Including label for supervised training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AH_389fOFVWL"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "vocab_size = len(vocab)  # Assuming vocab is already built as shown above\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v0JZd8RuFVWL"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Function to yield tokens from the IMDB dataset\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Load the dataset iterator\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "# Build the vocabulary from the iterator\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>', '<pad>', '<start>', '<end>'])\n",
        "\n",
        "# Set special tokens and their indexes\n",
        "vocab.set_default_index(vocab['<unk>'])  # Set default index for unknown tokens\n",
        "\n",
        "# Assuming you now have a 'vocab' object properly set up, you can proceed with using it in your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KMVGJw5dFVWL"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YmZo6A8bFVWL",
        "outputId": "10005a4f-1137-48ea-b6a7-a65c53d9d992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-bdf70b4b145c>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
            "<ipython-input-14-bdf70b4b145c>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.997613549232483\n",
            "Epoch 2, Loss: 2.9610719233751297\n",
            "Epoch 3, Loss: 2.9152935221791267\n",
            "Epoch 4, Loss: 2.8284693136811256\n",
            "Epoch 5, Loss: 2.6898324340581894\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# LSTMModel definition\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)  # Output layer maps to num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output)  # No need to select the last timestep unless it's sequence classification\n",
        "        return output\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, input_sequences, targets):\n",
        "        self.input_sequences = input_sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_sequences[idx], self.targets[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_sequences, targets = zip(*batch)\n",
        "    input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
        "    targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n",
        "    return input_sequences_padded, targets_padded\n",
        "\n",
        "vocab_size = 10000  # Example vocab size\n",
        "num_classes = 20  # Example number of classes\n",
        "\n",
        "input_sequences = torch.randint(0, vocab_size, (1000, 10))  # Adjust as necessary\n",
        "targets = torch.randint(0, num_classes, (1000, 10))  # Adjust as necessary\n",
        "\n",
        "dataset = TextDataset(input_sequences, targets)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim=100, hidden_dim=256, num_classes=num_classes)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Assuming you have a list called 'loss_values' that stores the average loss for each epoch\n",
        "loss_values = []\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_sequences, targets in train_loader:\n",
        "        input_sequences, targets = input_sequences.long(), targets.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(input_sequences)\n",
        "\n",
        "        loss = criterion(predictions.view(-1, num_classes), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    loss_values.append(average_loss)\n",
        "    print(f'Epoch {epoch+1}, Loss: {average_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Adjusted file path for Google Colab environment\n",
        "file_path = '/content/bul.txt'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "else:\n",
        "    print(\"File not found. Please check the file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Py6dYSNXNYKG",
        "outputId": "6a855a98-9bc3-4ee0-f996-c745518894c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "cxnSjUPzP3xM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings = {}\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example vocab list - replace with your actual vocab\n",
        "vocab = ['hello', 'world', '<unk>', '<pad>']  # Example vocabulary\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100  # Dimensionality of GloVe vectors you loaded\n",
        "weights_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Create a weights matrix to initialize the embedding layer\n",
        "for i, word in enumerate(vocab):\n",
        "    try:\n",
        "        weights_matrix[i] = glove_embeddings[word]\n",
        "    except KeyError:\n",
        "        # Initialize with a random vector if the word is not in GloVe\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n",
        "\n",
        "# Create an embedding layer and load the GloVe weights\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedding_layer.weight.data.copy_(torch.from_numpy(weights_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hKU0VfK2ib5s",
        "outputId": "efd39df1-2ed2-4962-89e9-a6d2aa519585"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.6688e-01,  3.9632e-01,  6.1690e-01, -7.7451e-01, -1.0390e-01,\n",
              "          2.6697e-01,  2.7880e-01,  3.0992e-01,  5.4685e-03, -8.5256e-02,\n",
              "          7.3602e-01, -9.8432e-02,  5.4790e-01, -3.0305e-02,  3.3479e-01,\n",
              "          1.4094e-01, -7.0003e-03,  3.2569e-01,  2.2902e-01,  4.6557e-01,\n",
              "         -1.9531e-01,  3.7491e-01, -7.1390e-01, -5.1775e-01,  7.7039e-01,\n",
              "          1.0881e+00, -6.6011e-01, -1.6234e-01,  9.1190e-01,  2.1046e-01,\n",
              "          4.7494e-02,  1.0019e+00,  1.1133e+00,  7.0094e-01, -8.6960e-02,\n",
              "          4.7571e-01,  1.6360e-01, -4.4469e-01,  4.4690e-01, -9.3817e-01,\n",
              "          1.3101e-02,  8.5964e-02, -6.7456e-01,  4.9662e-01, -3.7827e-02,\n",
              "         -1.1038e-01, -2.8612e-01,  7.4606e-02, -3.1527e-01, -9.3774e-02,\n",
              "         -5.7069e-01,  6.6865e-01,  4.5307e-01, -3.4154e-01, -7.1660e-01,\n",
              "         -7.5273e-01,  7.5212e-02,  5.7903e-01, -1.1910e-01, -1.1379e-01,\n",
              "         -1.0026e-01,  7.1341e-01, -1.1574e+00, -7.4026e-01,  4.0452e-01,\n",
              "          1.8023e-01,  2.1449e-01,  3.7638e-01,  1.1239e-01, -5.3639e-01,\n",
              "         -2.5092e-02,  3.1886e-01, -2.5013e-01, -6.3283e-01, -1.1843e-02,\n",
              "          1.3770e+00,  8.6013e-01,  2.0476e-01, -3.6815e-01, -6.8874e-01,\n",
              "          5.3512e-01, -4.6556e-01,  2.7389e-01,  4.1180e-01, -8.5400e-01,\n",
              "         -4.6288e-02,  1.1304e-01, -2.7326e-01,  1.5636e-01, -2.0334e-01,\n",
              "          5.3586e-01,  5.9784e-01,  6.0469e-01,  1.3735e-01,  4.2232e-01,\n",
              "         -6.1279e-01, -3.8486e-01,  3.5842e-01, -4.8464e-01,  3.0728e-01],\n",
              "        [ 4.9177e-01,  1.1164e+00,  1.1424e+00,  1.4381e-01, -1.0696e-01,\n",
              "         -4.6727e-01, -4.4374e-01, -8.8024e-03, -5.0406e-01, -2.0549e-01,\n",
              "          5.0910e-01, -6.0904e-01,  2.0980e-01, -4.4836e-01, -7.0383e-01,\n",
              "          2.1516e-01,  6.6189e-01,  3.4620e-01, -8.9294e-01, -4.8032e-01,\n",
              "          4.3069e-01,  3.5697e-01,  8.4277e-01,  5.2344e-01,  8.2065e-01,\n",
              "          5.3183e-04,  2.4835e-01, -2.0887e-01,  8.1657e-01,  2.5048e-01,\n",
              "         -7.4761e-01, -1.1309e-02, -4.7481e-01,  6.4520e-02,  5.4517e-01,\n",
              "          2.0714e-01, -4.6237e-01,  1.0724e+00, -1.0526e+00, -1.5567e-01,\n",
              "         -7.9339e-01, -2.8366e-02,  1.0138e-01, -2.0909e-01,  4.5513e-01,\n",
              "          4.7330e-01,  6.8859e-01, -2.3840e-01, -5.5178e-02, -8.3022e-01,\n",
              "         -4.7127e-01,  2.2713e-01,  4.2651e-02,  1.1273e+00, -8.4776e-02,\n",
              "         -3.0378e+00, -1.8389e-01,  7.8244e-01,  1.6395e+00,  7.6146e-01,\n",
              "         -1.4258e-01,  6.5115e-01, -1.3549e-02, -5.1465e-01,  6.6951e-01,\n",
              "         -3.4464e-01, -1.4525e-01,  4.9258e-01,  8.0085e-01, -5.4971e-01,\n",
              "          3.9657e-01, -4.8571e-01, -4.3846e-01,  3.3180e-01,  1.0356e-01,\n",
              "         -2.8987e-02,  1.0896e-01, -4.5671e-01, -1.1150e+00, -8.2366e-02,\n",
              "          1.0186e+00,  3.0639e-02, -3.7162e-01,  1.0742e+00, -1.0642e+00,\n",
              "         -2.0298e-01, -9.8434e-01, -3.2040e-01,  1.5969e-01, -1.7910e-01,\n",
              "          2.1325e-01,  4.7155e-01,  6.8247e-01,  1.3784e-01, -1.0704e-01,\n",
              "         -1.8294e-01, -4.0082e-01, -5.0885e-01,  6.2556e-01,  4.3917e-01],\n",
              "        [ 1.3107e+00,  1.2494e+00, -4.7686e-02,  8.4904e-02,  3.3185e-01,\n",
              "          4.3298e-03,  3.9922e-01, -5.0834e-01,  1.3358e-02,  6.0450e-02,\n",
              "         -4.0320e-01, -1.3239e-01, -5.6292e-02, -4.4821e-01,  4.3027e-01,\n",
              "         -5.2614e-01,  3.4394e-01, -7.5920e-01,  7.5699e-01,  7.3559e-01,\n",
              "          2.3563e-01, -3.3795e-01,  3.8131e-01, -1.8805e-02, -1.6856e-01,\n",
              "         -5.4905e-02, -6.3770e-01, -9.4111e-01, -8.9925e-01, -1.1561e-01,\n",
              "          3.9597e-01,  5.9107e-01, -6.9302e-01, -1.0128e-01, -1.1066e+00,\n",
              "         -9.5441e-01, -8.4082e-01,  1.3774e+00,  7.1179e-01, -9.8002e-02,\n",
              "          6.0134e-03, -6.2556e-01,  2.9477e-01,  5.7383e-01,  9.3235e-02,\n",
              "          8.0360e-02,  6.4480e-01,  1.2160e-01,  3.9778e-01, -5.9048e-01,\n",
              "          4.4336e-01, -4.5346e-01, -5.9738e-01,  8.0572e-01,  5.6627e-01,\n",
              "          3.3221e-01,  7.2166e-01, -6.3182e-01,  1.3345e-01,  1.2435e-01,\n",
              "         -1.3170e-01, -1.7726e-01,  2.1215e+00, -9.4593e-01,  3.2102e-01,\n",
              "          6.0188e-01, -3.4554e-01, -1.4543e-01, -8.0569e-01, -3.3913e-01,\n",
              "         -8.5657e-01, -9.4142e-01, -4.0183e-03, -6.6347e-01, -7.7928e-02,\n",
              "         -1.0165e+00,  3.9052e-01, -3.9935e-01,  9.1193e-01, -2.4202e-01,\n",
              "         -5.4791e-01, -7.6696e-01,  6.1689e-01,  1.0552e+00, -3.4469e-01,\n",
              "          2.3224e-01, -2.7841e-01, -5.7870e-01, -8.3034e-01,  8.3796e-01,\n",
              "         -4.4641e-01, -1.6860e-01, -1.2891e+00, -7.5538e-02, -7.4784e-02,\n",
              "         -5.8046e-01, -1.0862e+00, -3.7059e-01, -1.6261e-01,  1.0797e+00],\n",
              "        [-8.6562e-01,  9.2624e-01,  7.2108e-01, -6.1114e-01, -1.1374e+00,\n",
              "         -4.0395e-01, -2.7309e-02, -7.4359e-01,  3.8358e-02,  4.4115e-02,\n",
              "          1.5830e-02,  3.4450e-01, -7.2442e-01, -1.0555e+00,  1.9279e-01,\n",
              "          2.0444e-01,  2.3383e-01, -5.7670e-02, -7.5316e-01, -7.9025e-02,\n",
              "          1.5501e+00, -6.6442e-02, -9.9176e-01, -1.0540e+00,  3.9164e-01,\n",
              "          7.7027e-01, -4.2773e-01,  7.8262e-01,  4.5944e-01, -3.5622e-01,\n",
              "         -3.0648e-01, -5.5647e-01, -1.2766e+00,  6.7010e-01, -1.8289e-01,\n",
              "          1.8214e+00,  3.1675e-02, -1.2719e-01, -1.7105e-01, -1.0081e-01,\n",
              "          5.8258e-01,  1.7871e-01,  3.9542e-01,  1.1849e-02, -2.8377e-02,\n",
              "          2.3318e-02, -1.6572e-01, -5.6873e-01, -6.4058e-01,  3.7328e-01,\n",
              "          8.3925e-01,  8.2797e-02, -4.8610e-01, -1.2094e-01,  3.0516e-01,\n",
              "          4.8452e-01,  2.3791e-01,  1.0157e+00, -4.9648e-01,  3.2498e-01,\n",
              "          2.4428e-01,  7.1252e-01, -7.3106e-01, -4.1720e-01, -9.8640e-02,\n",
              "          3.0628e-01,  4.7593e-01, -5.9634e-01, -8.0583e-01, -1.4615e-02,\n",
              "          2.8354e-01,  4.8113e-02, -2.0202e-02,  1.8684e-01, -8.5424e-02,\n",
              "         -2.4930e-01, -7.3600e-01, -3.0259e-01, -5.4943e-01,  3.6934e-01,\n",
              "          7.9653e-02,  2.1859e-01, -9.0543e-01,  5.8671e-01, -6.1737e-01,\n",
              "         -4.1442e-01, -5.7089e-01,  1.9461e-01, -7.0001e-02,  7.3645e-01,\n",
              "          1.6141e-01, -4.2724e-01, -3.0098e-01, -8.8220e-01, -5.5974e-02,\n",
              "         -4.6337e-01, -4.3983e-01, -5.1777e-01,  1.2948e+00, -4.0998e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mypytorchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}