{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnormalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  \n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Define the display_top_predictions function\n",
    "def display_top_predictions(dataloader, model, feature_extractor, device, top_k=5):\n",
    "    model.eval()\n",
    "    feature_extractor.eval()\n",
    "    correct_pred = {classname: [] for classname in classes}\n",
    "    incorrect_pred = {classname: [] for classname in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            outputs = model(features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for i in range(len(images)):\n",
    "                label = labels[i]\n",
    "                pred = preds[i]\n",
    "                if pred == label:\n",
    "                    correct_pred[classes[label.item()]].append(images[i])\n",
    "                else:\n",
    "                    incorrect_pred[classes[label.item()]].append(images[i])\n",
    "\n",
    "    for classname, image_list in correct_pred.items():\n",
    "        print(f'\\nTop 5 correct predictions for class {classname}:')\n",
    "        for i, image in enumerate(image_list[:top_k]):\n",
    "            imshow(F.to_pil_image(torchvision.utils.make_grid(image)))\n",
    "            print(f'Image {i+1}: Correctly predicted as {classname}')\n",
    "\n",
    "    for classname, image_list in incorrect_pred.items():\n",
    "        print(f'\\nTop 5 incorrect predictions for class {classname}:')\n",
    "        for i, image in enumerate(image_list[:top_k]):\n",
    "            imshow(F.to_pil_image(torchvision.utils.make_grid(image)))\n",
    "            print(f'Image {i+1}: Incorrectly predicted as {classname}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic regression model...\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 dataset loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model definitions\n",
    "resnet = resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc = nn.Linear(512, 10)  # 512 for ResNet18 output, 10 for CIFAR-10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "logistic_regression_model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(logistic_regression_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function for logistic regression\n",
    "def train_logistic_regression_model(model, feature_extractor, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    feature_extractor.eval()  # Feature extractor is in eval mode\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                features = feature_extractor(inputs)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 200 == 199:\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Training function for finetuning ResNet model\n",
    "def train_finetuned_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 200 == 199:\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, feature_extractor, test_loader):\n",
    "    model.eval()\n",
    "    feature_extractor.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            features = feature_extractor(inputs)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Assuming 'classes' is a list of class names in the order they are indexed by the model\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Train and evaluate logistic regression model\n",
    "print(\"Training logistic regression model...\")\n",
    "train_logistic_regression_model(logistic_regression_model, resnet, trainloader, criterion, optimizer, num_epochs=5)\n",
    "evaluate_model(logistic_regression_model, resnet, testloader)\n",
    "\n",
    "# Fine-tune the entire ResNet18 model\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer_ft = Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Finetuning the ResNet18 model...\")\n",
    "train_finetuned_model(resnet, trainloader, criterion, optimizer_ft, num_epochs=5)\n",
    "evaluate_model(logistic_regression_model, resnet, testloader)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Displaying top predictions for the logistic regression model...\")\n",
    "display_top_predictions(testloader, logistic_regression_model, resnet, device, top_k=5)\n",
    "print(\"Displaying top predictions for the finetuned ResNet18 model...\")\n",
    "display_top_predictions(testloader, resnet, resnet, device, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the MovieLens dataset\n",
    "ratings_path = '/Users/student/Desktop/SPRING 24/IDS 576/ml-latest-small/ratings.csv' \n",
    "movies_path = '/Users/student/Desktop/SPRING 24/IDS 576/ml-latest-small/movies.csv'   \n",
    "\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "movies = pd.read_csv(movies_path)\n",
    "\n",
    "# Convert ratings to a binary preference\n",
    "ratings['like'] = (ratings['rating'] >= 3.5).astype(int)\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_table = ratings.pivot(index='userId', columns='movieId', values='like').fillna(0)\n",
    "\n",
    "# Create a co-occurrence matrix\n",
    "cooccurrence_matrix = pivot_table.T.dot(pivot_table)\n",
    "np.fill_diagonal(cooccurrence_matrix.values, 0)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_ij = torch.tensor(cooccurrence_matrix.values, dtype=torch.float32)\n",
    "\n",
    "# Number of movies\n",
    "num_movies = X_ij.shape[0]\n",
    "\n",
    "# Initialize embeddings\n",
    "V = Variable(torch.rand(num_movies, 50), requires_grad=True)\n",
    "\n",
    "# Define the optimization function\n",
    "def cost_function(V, X_ij):\n",
    "    VtV = torch.matmul(V, V.t())\n",
    "    loss = (VtV - X_ij).pow(2).sum()\n",
    "    return loss\n",
    "\n",
    "# Optimization setup\n",
    "optimizer = SGD([V], lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = cost_function(V, X_ij)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Plot the loss over epochs\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Function to get movie recommendations\n",
    "def get_movie_recommendations(movie_title, movie_embeddings, movies_df, k=10):\n",
    "    movie_id = movies_df.loc[movies_df['title'] == movie_title, 'movieId'].item()\n",
    "    movie_idx = movie_to_idx[movie_id]\n",
    "    query_embedding = movie_embeddings[movie_idx].reshape(1, -1)\n",
    "    similarity = cosine_similarity(query_embedding, movie_embeddings.detach().numpy())\n",
    "    top_k_indices = similarity[0].argsort()[-k:][::-1]\n",
    "    \n",
    "    recommendations = movies_df.iloc[top_k_indices]['title'].values\n",
    "    return recommendations\n",
    "\n",
    "# Create a mapping from movieId to index and vice versa\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(cooccurrence_matrix.columns)}\n",
    "idx_to_movie = {idx: movie for movie, idx in movie_to_idx.items()}\n",
    "\n",
    "# Get recommendations for a movie\n",
    "recommended_movies = get_movie_recommendations('Apollo 13 (1995)', V, movies, k=10)\n",
    "print(\"Movies recommended based on 'Apollo 13 (1995)':\")\n",
    "for movie in recommended_movies:\n",
    "    print(movie)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
