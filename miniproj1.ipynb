{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josecuervo420/576a2/blob/main/miniproj1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3m_2cazdKVG",
        "outputId": "b75c51fd-3ed2-483c-c7fe-789c0f6a9503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from nltk.corpus import brown\n",
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "# Ensure you have the Brown corpus downloaded:\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "# Retrieve the sentences from the Brown corpus\n",
        "brown_sentences = brown.sents()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation, and test sets\n",
        "D_train = brown_sentences[:40138]\n",
        "D_val = brown_sentences[40138:45872]\n",
        "D_test = brown_sentences[45872:]\n",
        "\n",
        "# Function to build a unigram model\n",
        "def build_unigram_model(sentences):\n",
        "    model = Counter()\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            model[word] += 1\n",
        "    total_count = sum(model.values())\n",
        "    for word in model:\n",
        "        model[word] /= total_count\n",
        "    return model\n",
        "\n",
        "# Function to build a bigram model\n",
        "def build_bigram_model(sentences):\n",
        "    model = defaultdict(Counter)\n",
        "    for sentence in sentences:\n",
        "        previous_word = None\n",
        "        for word in sentence:\n",
        "            if previous_word is not None:\n",
        "                model[previous_word][word] += 1\n",
        "            previous_word = word\n",
        "    for previous_word in model:\n",
        "        total_count = sum(model[previous_word].values())\n",
        "        for word in model[previous_word]:\n",
        "            model[previous_word][word] /= total_count\n",
        "    return model\n",
        "\n",
        "# Function to calculate perplexity\n",
        "def calculate_perplexity(model, sentences, n_gram=1):\n",
        "    perplexity = 1\n",
        "    N = 0\n",
        "    for sentence in sentences:\n",
        "        for i in range(len(sentence) - n_gram + 1):\n",
        "            if n_gram == 1:\n",
        "                word = sentence[i]\n",
        "                # Using a small value to avoid log(0)\n",
        "                word_probability = model.get(word, 1e-6)\n",
        "            else:\n",
        "                previous_word = sentence[i-1] if i > 0 else None\n",
        "                word = sentence[i]\n",
        "                word_probability = model[previous_word].get(word, 1e-6)  # Using a small value to avoid log(0)\n",
        "            perplexity = perplexity * (1 / word_probability)\n",
        "            N += 1\n",
        "    perplexity = math.pow(perplexity, 1/float(N))\n",
        "    return perplexity"
      ],
      "metadata": {
        "id": "lw9FXVb-_llu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build unigram and bigram models\n",
        "unigram_model = build_unigram_model(D_train)\n",
        "bigram_model = build_bigram_model(D_train)\n",
        "\n",
        "# Calculate perplexity\n",
        "unigram_perplexity_train = calculate_perplexity(unigram_model, D_train)\n",
        "bigram_perplexity_train = calculate_perplexity(bigram_model, D_train, n_gram=2)\n",
        "unigram_perplexity_test = calculate_perplexity(unigram_model, D_test)\n",
        "bigram_perplexity_test = calculate_perplexity(bigram_model, D_test, n_gram=2)\n",
        "\n",
        "# Print the perplexities\n",
        "print(f\"Unigram Perplexity on Training Data: {unigram_perplexity_train}\")\n",
        "print(f\"Bigram Perplexity on Training Data: {bigram_perplexity_train}\")\n",
        "print(f\"Unigram Perplexity on Test Data: {unigram_perplexity_test}\")\n",
        "print(f\"Bigram Perplexity on Test Data: {bigram_perplexity_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxiZuuUF_sVZ",
        "outputId": "1e37d1a1-7a31-4896-e4f2-d8a50688acf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Perplexity on Training Data: inf\n",
            "Bigram Perplexity on Training Data: inf\n",
            "Unigram Perplexity on Test Data: inf\n",
            "Bigram Perplexity on Test Data: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement add-λ smoothing method for unigram model\n",
        "def add_lambda_smoothing_unigram(unigram_model, lambda_, vocabulary_size):\n",
        "    smoothed_model = {}\n",
        "    total_count = sum(unigram_model.values())\n",
        "    for word, count in unigram_model.items():\n",
        "        smoothed_model[word] = (count + lambda_) / (total_count + lambda_ * vocabulary_size)\n",
        "    return smoothed_model\n",
        "\n",
        "# Implement add-λ smoothing method for bigram model\n",
        "def add_lambda_smoothing_bigram(bigram_model, lambda_, vocabulary_size):\n",
        "    smoothed_model = defaultdict(lambda: defaultdict(float))\n",
        "    for previous_word, word_counts in bigram_model.items():\n",
        "        total_count = sum(word_counts.values())\n",
        "        for word, count in word_counts.items():\n",
        "            smoothed_model[previous_word][word] = (count + lambda_) / (total_count + lambda_ * vocabulary_size)\n",
        "    return smoothed_model\n",
        "\n",
        "# Perform a grid search over a range of λ values for unigram model\n",
        "lambda_values = np.linspace(0.1, 2.0, 20)  # Example range, adjust as needed\n",
        "best_lambda_unigram = lambda_values[0]\n",
        "best_perplexity_unigram = float('inf')\n",
        "\n",
        "for lambda_ in lambda_values:\n",
        "    smoothed_model = add_lambda_smoothing_unigram(unigram_model, lambda_, len(unigram_model))\n",
        "    perplexity = calculate_perplexity(smoothed_model, D_val)\n",
        "    print(f\"λ = {lambda_}, Unigram Perplexity = {perplexity}\")\n",
        "\n",
        "    if perplexity < best_perplexity_unigram:\n",
        "        best_perplexity_unigram = perplexity\n",
        "        best_lambda_unigram = lambda_\n",
        "\n",
        "print(f\"Best λ for Unigram: {best_lambda_unigram}, with perplexity: {best_perplexity_unigram}\")\n",
        "\n",
        "# Perform a grid search over a range of λ values for bigram model\n",
        "best_lambda_bigram = lambda_values[0]\n",
        "best_perplexity_bigram = float('inf')\n",
        "\n",
        "for lambda_ in lambda_values:\n",
        "    smoothed_model = add_lambda_smoothing_bigram(bigram_model, lambda_, len(unigram_model))\n",
        "    perplexity = calculate_perplexity(smoothed_model, D_val, n_gram=2)\n",
        "    print(f\"λ = {lambda_}, Bigram Perplexity = {perplexity}\")\n",
        "\n",
        "    if perplexity < best_perplexity_bigram:\n",
        "        best_perplexity_bigram = perplexity\n",
        "        best_lambda_bigram = lambda_\n",
        "\n",
        "print(f\"Best λ for Bigram: {best_lambda_bigram}, with perplexity: {best_perplexity_bigram}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbEmqSnV_2Ab",
        "outputId": "8005b4c2-96ae-4213-bd3a-3a372e16735d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-658fbc767def>:46: RuntimeWarning: overflow encountered in scalar multiply\n",
            "  perplexity = perplexity * (1 / word_probability)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "λ = 0.1, Unigram Perplexity = inf\n",
            "λ = 0.2, Unigram Perplexity = inf\n",
            "λ = 0.3, Unigram Perplexity = inf\n",
            "λ = 0.4, Unigram Perplexity = inf\n",
            "λ = 0.5, Unigram Perplexity = inf\n",
            "λ = 0.6, Unigram Perplexity = inf\n",
            "λ = 0.7, Unigram Perplexity = inf\n",
            "λ = 0.7999999999999999, Unigram Perplexity = inf\n",
            "λ = 0.8999999999999999, Unigram Perplexity = inf\n",
            "λ = 0.9999999999999999, Unigram Perplexity = inf\n",
            "λ = 1.0999999999999999, Unigram Perplexity = inf\n",
            "λ = 1.2, Unigram Perplexity = inf\n",
            "λ = 1.3, Unigram Perplexity = inf\n",
            "λ = 1.4, Unigram Perplexity = inf\n",
            "λ = 1.5, Unigram Perplexity = inf\n",
            "λ = 1.5999999999999999, Unigram Perplexity = inf\n",
            "λ = 1.7, Unigram Perplexity = inf\n",
            "λ = 1.8, Unigram Perplexity = inf\n",
            "λ = 1.9, Unigram Perplexity = inf\n",
            "λ = 2.0, Unigram Perplexity = inf\n",
            "Best λ for Unigram: 0.1, with perplexity: inf\n",
            "λ = 0.1, Bigram Perplexity = inf\n",
            "λ = 0.2, Bigram Perplexity = inf\n",
            "λ = 0.3, Bigram Perplexity = inf\n",
            "λ = 0.4, Bigram Perplexity = inf\n",
            "λ = 0.5, Bigram Perplexity = inf\n",
            "λ = 0.6, Bigram Perplexity = inf\n",
            "λ = 0.7, Bigram Perplexity = inf\n",
            "λ = 0.7999999999999999, Bigram Perplexity = inf\n",
            "λ = 0.8999999999999999, Bigram Perplexity = inf\n",
            "λ = 0.9999999999999999, Bigram Perplexity = inf\n",
            "λ = 1.0999999999999999, Bigram Perplexity = inf\n",
            "λ = 1.2, Bigram Perplexity = inf\n",
            "λ = 1.3, Bigram Perplexity = inf\n",
            "λ = 1.4, Bigram Perplexity = inf\n",
            "λ = 1.5, Bigram Perplexity = inf\n",
            "λ = 1.5999999999999999, Bigram Perplexity = inf\n",
            "λ = 1.7, Bigram Perplexity = inf\n",
            "λ = 1.8, Bigram Perplexity = inf\n",
            "λ = 1.9, Bigram Perplexity = inf\n",
            "λ = 2.0, Bigram Perplexity = inf\n",
            "Best λ for Bigram: 0.1, with perplexity: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine training and validation data for retraining\n",
        "D_train_val = D_train + D_val\n",
        "\n",
        "# Retrain unigram and bigram models with the combined data using best λ values\n",
        "unigram_model_retrained = add_lambda_smoothing_unigram(build_unigram_model(D_train_val), best_lambda_unigram, len(unigram_model))\n",
        "bigram_model_retrained = add_lambda_smoothing_bigram(build_bigram_model(D_train_val), best_lambda_bigram, len(unigram_model))\n",
        "\n",
        "# Calculate perplexity of the retrained models on the test data\n",
        "unigram_perplexity_test_retrained = calculate_perplexity(unigram_model_retrained, D_test)\n",
        "bigram_perplexity_test_retrained = calculate_perplexity(bigram_model_retrained, D_test, n_gram=2)\n",
        "\n",
        "print(f\"Retrained Unigram Perplexity on Test Data: {unigram_perplexity_test_retrained}\")\n",
        "print(f\"Retrained Bigram Perplexity on Test Data: {bigram_perplexity_test_retrained}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV7XxsUY_6DK",
        "outputId": "5d80e4f0-2195-4da0-e68d-80ee6911820d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-658fbc767def>:46: RuntimeWarning: overflow encountered in scalar multiply\n",
            "  perplexity = perplexity * (1 / word_probability)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrained Unigram Perplexity on Test Data: inf\n",
            "Retrained Bigram Perplexity on Test Data: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random sentences from the unigram and bigram models\n",
        "def generate_sentence_from_model(model, stop_symbol, is_bigram=False):\n",
        "    sentence = []\n",
        "    if is_bigram:\n",
        "        word = '<s>'  # Assuming <s> is your start symbol\n",
        "        while True:\n",
        "            next_words = list(model[word].keys())\n",
        "            probabilities = list(model[word].values())\n",
        "            next_word = random.choices(next_words, weights=probabilities)[0]\n",
        "            if next_word == stop_symbol or next_word == '</s>':\n",
        "                break\n",
        "            sentence.append(next_word)\n",
        "            word = next_word\n",
        "    else:\n",
        "        while True:\n",
        "            next_words = list(model.keys())\n",
        "            probabilities = list(model.values())\n",
        "            next_word = random.choices(next_words, weights=probabilities)[0]\n",
        "            if next_word == stop_symbol:\n",
        "                break\n",
        "            sentence.append(next_word)\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "# Generate sentences from the retrained unigram and bigram models\n",
        "print(\"Generated sentences from the unigram model:\")\n",
        "for _ in range(5):\n",
        "    print(generate_sentence_from_model(unigram_model_retrained, '</s>'))\n",
        "\n",
        "print(\"\\nGenerated sentences from the bigram model:\")\n",
        "for _ in range(5):\n",
        "    print(generate_sentence_from_model(bigram_model_retrained, '</s>', is_bigram=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_HK2qvAABf",
        "outputId": "3a99519a-9537-4adc-8989-df2b4bd698c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentences from the unigram model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a trigram model trained\n",
        "def generate_sentence_from_trigram(model, stop_symbol):\n",
        "    sentence = ['<s>', '<s>']  # Assuming <s> is your start symbol\n",
        "    while True:\n",
        "        context = tuple(sentence[-2:])\n",
        "        if context not in model:\n",
        "            break\n",
        "        next_words = list(model[context].keys())\n",
        "        probabilities = list(model[context].values())\n",
        "        next_word = random.choices(next_words, weights=probabilities)[0]\n",
        "        if next_word == stop_symbol or next_word == '</s>':\n",
        "            break\n",
        "        sentence.append(next_word)\n",
        "    return ' '.join(sentence[2:])\n",
        "\n",
        "# Generate sentences from the trigram model\n",
        "print(\"\\nGenerated sentences from the trigram model:\")\n",
        "for _ in range(5):\n",
        "    print(generate_sentence_from_trigram(trigram_model_retrained, '</s>'))"
      ],
      "metadata": {
        "id": "MxsIS1VGEeph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}